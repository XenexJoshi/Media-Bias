{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential modules for the machine-learning process\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>heading</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>bias_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>['Protests', 'Fourth Of July', 'Gun Control An...</td>\n",
       "      <td>Chicago Gun Violence Spikes and Increasingly F...</td>\n",
       "      <td>New York Times (News)</td>\n",
       "      <td>As Yasmin Miller drove home from a laundromat ...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>['Protests', 'Fourth Of July', 'Gun Control An...</td>\n",
       "      <td>‘Bullets just came from nowhere’: Fourth of Ju...</td>\n",
       "      <td>Chicago Tribune</td>\n",
       "      <td>As many Chicagoans were celebrating the Fourth...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>['Protests', 'Fourth Of July', 'Gun Control An...</td>\n",
       "      <td>Dozens of shootings across US mark bloody July...</td>\n",
       "      <td>New York Post (News)</td>\n",
       "      <td>The nation’s 4th of July weekend was marred by...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yellen Warns Congress of 'Economic Recession' ...</td>\n",
       "      <td>['Janet Yellen', 'Debt Ceiling', 'Economic Pol...</td>\n",
       "      <td>Federal Government Will Run Out of Cash on Oct...</td>\n",
       "      <td>The Epoch Times</td>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday war...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yellen Warns Congress of 'Economic Recession' ...</td>\n",
       "      <td>['Janet Yellen', 'Debt Ceiling', 'Economic Pol...</td>\n",
       "      <td>Yellen tells Congress that U.S. will run out o...</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday tol...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0           Gun Violence Over Fourth of July Weekend   \n",
       "1   1           Gun Violence Over Fourth of July Weekend   \n",
       "2   2           Gun Violence Over Fourth of July Weekend   \n",
       "3   3  Yellen Warns Congress of 'Economic Recession' ...   \n",
       "4   4  Yellen Warns Congress of 'Economic Recession' ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['Protests', 'Fourth Of July', 'Gun Control An...   \n",
       "1  ['Protests', 'Fourth Of July', 'Gun Control An...   \n",
       "2  ['Protests', 'Fourth Of July', 'Gun Control An...   \n",
       "3  ['Janet Yellen', 'Debt Ceiling', 'Economic Pol...   \n",
       "4  ['Janet Yellen', 'Debt Ceiling', 'Economic Pol...   \n",
       "\n",
       "                                             heading                 source  \\\n",
       "0  Chicago Gun Violence Spikes and Increasingly F...  New York Times (News)   \n",
       "1  ‘Bullets just came from nowhere’: Fourth of Ju...        Chicago Tribune   \n",
       "2  Dozens of shootings across US mark bloody July...   New York Post (News)   \n",
       "3  Federal Government Will Run Out of Cash on Oct...        The Epoch Times   \n",
       "4  Yellen tells Congress that U.S. will run out o...        Washington Post   \n",
       "\n",
       "                                                text bias_rating  \n",
       "0  As Yasmin Miller drove home from a laundromat ...        left  \n",
       "1  As many Chicagoans were celebrating the Fourth...      center  \n",
       "2  The nation’s 4th of July weekend was marred by...       right  \n",
       "3  Treasury Secretary Janet Yellen on Tuesday war...       right  \n",
       "4  Treasury Secretary Janet Yellen on Tuesday tol...        left  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the source dataset obtained from source: https://github.com/irgroup/Qbias\n",
    "dataset = pd.read_csv(\"bias_data.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>bias_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>As Yasmin Miller drove home from a laundromat ...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>As many Chicagoans were celebrating the Fourth...</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Gun Violence Over Fourth of July Weekend</td>\n",
       "      <td>The nation’s 4th of July weekend was marred by...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Yellen Warns Congress of 'Economic Recession' ...</td>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday war...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Yellen Warns Congress of 'Economic Recession' ...</td>\n",
       "      <td>Treasury Secretary Janet Yellen on Tuesday tol...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0           Gun Violence Over Fourth of July Weekend   \n",
       "1   1           Gun Violence Over Fourth of July Weekend   \n",
       "2   2           Gun Violence Over Fourth of July Weekend   \n",
       "3   3  Yellen Warns Congress of 'Economic Recession' ...   \n",
       "4   4  Yellen Warns Congress of 'Economic Recession' ...   \n",
       "\n",
       "                                                text bias_rating  \n",
       "0  As Yasmin Miller drove home from a laundromat ...        left  \n",
       "1  As many Chicagoans were celebrating the Fourth...      center  \n",
       "2  The nation’s 4th of July weekend was marred by...       right  \n",
       "3  Treasury Secretary Janet Yellen on Tuesday war...       right  \n",
       "4  Treasury Secretary Janet Yellen on Tuesday tol...        left  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the essential data columns for the text-based media bias classification\n",
    "bias_data  = dataset[['id', 'title', 'text', 'bias_rating']]\n",
    "input_text = bias_data['text'].astype(str)\n",
    "input_label = bias_data['bias_rating'].astype(str)\n",
    "bias_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Splitting data in 70-30 training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_text, input_label, test_size = 0.30, random_state = 42)\n",
    "\n",
    "# Generating bag-of-words for Naive-Bayes and SVM, after pre-processing by removing standard English stopwords and converting \n",
    "# text to lowercase\n",
    "vectorizer = CountVectorizer(stop_words = \"english\", lowercase = True)\n",
    "train_vector = vectorizer.fit_transform(x_train)\n",
    "test_vector = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the naive bayes classifier is: 44.599%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Training the Multinomial Naive Bayes Model on the vectorized bag-of-words training set\n",
    "naive_bayes_model = MultinomialNB()\n",
    "naive_bayes_model.fit(train_vector, y_train)\n",
    "\n",
    "# Generating prediction on the vectorized testing set\n",
    "y_pred = naive_bayes_model.predict(test_vector)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of the naive bayes classifier is: \" + str(round(100 * accuracy, 3)) + \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the SVM classifier is: 41.351%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Training an SVM with linear kernel on the training data\n",
    "# Using a linear kernel to leverage its simplicity and faster training time compared to more fine-tuned SVMs\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(train_vector, y_train)\n",
    "\n",
    "# Getting linear SVM predictions on the testing set\n",
    "y_pred = svm_model.predict(test_vector)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of the SVM classifier is: \" + str(round(100 * accuracy, 3)) + \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=  47.7s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=  47.6s\n",
      "[CV] END ..................C=0.01, gamma=0.01, kernel=linear; total time=  49.1s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=  55.5s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=  54.0s\n",
      "[CV] END .....................C=0.01, gamma=0.01, kernel=rbf; total time=  54.7s\n",
      "[CV] END ...................C=0.01, gamma=0.1, kernel=linear; total time=  48.3s\n",
      "[CV] END ...................C=0.01, gamma=0.1, kernel=linear; total time=  49.5s\n",
      "[CV] END ...................C=0.01, gamma=0.1, kernel=linear; total time=  47.9s\n",
      "[CV] END ......................C=0.01, gamma=0.1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ......................C=0.01, gamma=0.1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ......................C=0.01, gamma=0.1, kernel=rbf; total time= 1.0min\n",
      "[CV] END .....................C=0.01, gamma=1, kernel=linear; total time=  48.3s\n",
      "[CV] END .....................C=0.01, gamma=1, kernel=linear; total time=  48.6s\n",
      "[CV] END .....................C=0.01, gamma=1, kernel=linear; total time=  49.0s\n",
      "[CV] END ........................C=0.01, gamma=1, kernel=rbf; total time=  59.9s\n",
      "[CV] END ........................C=0.01, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ........................C=0.01, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=  49.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=  48.9s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=  48.3s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  55.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  55.4s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=  54.9s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=  48.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=  50.5s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=  48.6s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 1.1min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 1.0min\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time= 1.0min\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=  48.2s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=  48.4s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=  48.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time= 1.0min\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time= 1.0min\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time= 1.1min\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=  58.5s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  54.4s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  55.7s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=  55.2s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time= 1.0min\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=  59.7s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 1.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 1.1min\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time= 1.1min\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time= 1.0min\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time= 1.1min\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=  59.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 1.2min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 1.1min\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time= 1.1min\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.1min\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=  60.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time= 1.0min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 1.3min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 1.2min\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time= 1.2min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.0min\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time= 1.1min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 1.6min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 1.6min\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time= 1.6min\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time= 1.0min\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time= 1.0min\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time= 1.0min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time= 2.1min\n",
      "The accuracy of the SVM(with 3-CV) classifier is: 50.069%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Selecting an array of hyperparameters for hyperparameter tuning using GridSearchCV() function\n",
    "parameters = {\n",
    "  'C' : [0.01, 0.1, 1, 10],\n",
    "  'kernel' : ['linear', 'rbf'],\n",
    "  'gamma' : [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "# Setting up the hyperparameter tunings\n",
    "svm_cv_model = GridSearchCV( estimator = SVC(),\n",
    "                         param_grid = parameters,\n",
    "                         cv = 3,\n",
    "                         verbose = 2\n",
    ")\n",
    "\n",
    "# Running GridSearchCV() on training set\n",
    "svm_cv_model.fit(train_vector, y_train)\n",
    "\n",
    "# Getting prediction on testing set\n",
    "y_pred = svm_cv_model.predict(test_vector)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of the SVM(with 3-CV) classifier is: \" + str(round(100 * accuracy, 3)) + \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xenexjoshi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    yasmin miller drove home laundromat englewood ...\n",
       "1    many chicagoans celebrating fourth july barbec...\n",
       "2    july weekend marred wrong kind spate shootings...\n",
       "3    treasury secretary janet yellen tuesday warned...\n",
       "4    treasury secretary janet yellen tuesday told c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Downloading stopwords form nltk.corpus for pre-processing input_text for CNN\n",
    "nltk.download('stopwords')\n",
    "filter = set(stopwords.words('english'))\n",
    "\n",
    "# Pre-processing function that removes the stopwords, and converts all words to lowercase for feeding into the CNN\n",
    "def preprocess(input, filter):\n",
    "  input = input.lower()\n",
    "  tags = input.split()\n",
    "  tags = [i for i in tags if i.isalpha() and i not in filter]\n",
    "  return \" \".join(tags)\n",
    "\n",
    "# Applying the custom pre-processing function on the input dataset\n",
    "input_text = input_text.apply(lambda x: preprocess(x, filter))\n",
    "input_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 ... 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "# Initializing the LabelEncoder() to encode the labels on the dataset\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Encoding input labels into integers(0, 1, 2)\n",
    "input_label = encoder.fit_transform(input_label)\n",
    "print(input_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ... 14419    12  4215]\n",
      " [    0     0     0 ...   433   230   524]\n",
      " [    0     0     0 ...  4012  1515   120]\n",
      " ...\n",
      " [    0     0     0 ...   904  1212    66]\n",
      " [    0     0     0 ...   558   919   670]\n",
      " [    0     0     0 ...   102    15   782]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Max word-count for the CNN tokenizer\n",
    "word_count = 20000\n",
    "\n",
    "# Initializing the Tokenizer, and fitting the input text using the Tokeinizer()\n",
    "tokenizer = Tokenizer(num_words = word_count)\n",
    "tokenizer.fit_on_texts(input_text)\n",
    "\n",
    "# Generating tokenized sequence from tokenizer, and padding sequence to ensure constant length inputs\n",
    "sequences = tokenizer.texts_to_sequences(input_text)\n",
    "input_text = pad_sequences(sequences, maxlen = 200)\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting bias_data.csv into 70-30 training set and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(input_text, input_label, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CNN parameters\n",
    "vocab_size = 20000\n",
    "embedding_dim = 128\n",
    "max_length = 200\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xenexjoshi/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m2,560,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m20,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,581,667</span> (9.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,581,667\u001b[0m (9.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,581,667</span> (9.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,581,667\u001b[0m (9.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implementing a single convolution layer CNN with Dropout layer to avoid overfitting\n",
    "model = tf.keras.Sequential([tf.keras.layers.Embedding(input_dim = word_count, output_dim = embedding_dim, input_length = max_length),\n",
    "                            tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)),\n",
    "                            tf.keras.layers.GlobalMaxPooling1D(),\n",
    "                            tf.keras.layers.Dense(32, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01)),\n",
    "                            tf.keras.layers.Dropout(0.5),\n",
    "                            tf.keras.layers.Dense(3, activation = 'softmax')])\n",
    "\n",
    "# Building CNN model based on the set CNN parameters \n",
    "model.build((None, max_length))\n",
    "\n",
    "# Compiling CNN model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# Generating CNN model report\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 28ms/step - accuracy: 0.4575 - loss: 1.3454 - val_accuracy: 0.4846 - val_loss: 1.0439\n",
      "Epoch 2/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4777 - loss: 1.0435 - val_accuracy: 0.4846 - val_loss: 1.0396\n",
      "Epoch 3/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.4739 - loss: 1.0427 - val_accuracy: 0.4846 - val_loss: 1.0361\n",
      "Epoch 4/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4682 - loss: 1.0410 - val_accuracy: 0.4846 - val_loss: 1.0390\n",
      "Epoch 5/5\n",
      "\u001b[1m429/429\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.4704 - loss: 1.0202 - val_accuracy: 0.4800 - val_loss: 1.0526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14ac76af0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Setting epoch count for the CNN training\n",
    "num_epochs = 5\n",
    "\n",
    "# Implementing an early-stopping to avoid overfitting onto the training set\n",
    "early_stopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience = 1.5,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "# Initiating the CNN training\n",
    "model.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size, validation_split = 0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4752 - loss: 1.0391\n",
      "The accuracy of the CNN classifier is: 46.913%.\n"
     ]
    }
   ],
   "source": [
    "# Generating the prediction report of the CNN on the testing set\n",
    "_, accuracy= model.evaluate(x_test, y_test)\n",
    "print(\"The accuracy of the CNN classifier is: \" + str(round(100 * accuracy, 3)) + \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>bias_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New York Times (News)</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chicago Tribune</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>New York Post (News)</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Epoch Times</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 source bias_rating\n",
       "0   0  New York Times (News)        left\n",
       "1   1        Chicago Tribune      center\n",
       "2   2   New York Post (News)       right\n",
       "3   3        The Epoch Times       right\n",
       "4   4        Washington Post        left"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the dataset into columns for news source based prediction\n",
    "source_bias = dataset[['id', 'source', 'bias_rating']]\n",
    "input_source = source_bias['source'].astype(str)\n",
    "input_tag = source_bias['bias_rating'].astype(str)\n",
    "source_bias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialing a LabelEncoder() to encode the labels\n",
    "encoder_tags = LabelEncoder()\n",
    "\n",
    "# Fitting the encoder on the bias labels\n",
    "encoder_tags.fit_transform(input_tag)\n",
    "\n",
    "# Splitting bias_data.csv into 70-30 training set and testing set\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(input_source, input_tag, test_size = 0.30, random_state = 42)\n",
    "\n",
    "# Applying the encoder on the training and testing set labels\n",
    "y_tr = encoder_tags.fit(y_tr)\n",
    "y_te = encoder_tags.fit(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the naive bayes classifier is: 96.415%.\n"
     ]
    }
   ],
   "source": [
    "# Initializing bag-of-words with english stopwords and lowercased data\n",
    "vectorizer = CountVectorizer(stop_words = \"english\", lowercase = True)\n",
    "\n",
    "# Generating a vectorized bag-of-words on the training and testing set\n",
    "train_vector = vectorizer.fit_transform(x_tr)\n",
    "test_vector = vectorizer.transform(x_te)\n",
    "\n",
    "# Initializing a Multinomial Naive-Bayes classifier\n",
    "naive_bayes_source = MultinomialNB()\n",
    "\n",
    "# Training the naive-bayes model on the training set\n",
    "naive_bayes_source.fit(train_vector, y_train)\n",
    "\n",
    "# Predicting the trained model on the testing set\n",
    "y_pred = naive_bayes_source.predict(test_vector)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of the naive bayes classifier is: \" + str(round(100 * accuracy, 3)) + \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "The predicted bias of BBC News is center.\n",
      "[1]\n",
      "The predicted bias of New York Times is left.\n",
      "[2]\n",
      "The predicted bias of Fox News is right.\n"
     ]
    }
   ],
   "source": [
    "# Implementing a callable classifer function that classifies the news source to its affiliated political bias\n",
    "def predict_bias(source):\n",
    "  src = vectorizer.transform([source])\n",
    "  result = naive_bayes_source.predict(src)\n",
    "  print(result)\n",
    "  bias = encoder_tags.inverse_transform(result)[0]\n",
    "  output_str = \"The predicted bias of \" + source + \" is \" + str(bias) + \".\"\n",
    "  return output_str\n",
    "\n",
    "print(predict_bias(\"BBC News\"))\n",
    "print(predict_bias(\"New York Times\"))\n",
    "print(predict_bias(\"Fox News\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
